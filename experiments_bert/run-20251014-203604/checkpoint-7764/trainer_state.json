{
  "best_metric": 0.6117752645542724,
  "best_model_checkpoint": "experiments_bert/run-20251014-203604/checkpoint-5176",
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 7764,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03863987635239567,
      "grad_norm": 2.792250633239746,
      "learning_rate": 1.9871200412158684e-05,
      "loss": 2.1339,
      "step": 50
    },
    {
      "epoch": 0.07727975270479134,
      "grad_norm": 3.028048038482666,
      "learning_rate": 1.9742400824317366e-05,
      "loss": 1.7446,
      "step": 100
    },
    {
      "epoch": 0.11591962905718702,
      "grad_norm": 4.253394603729248,
      "learning_rate": 1.9613601236476045e-05,
      "loss": 1.5603,
      "step": 150
    },
    {
      "epoch": 0.1545595054095827,
      "grad_norm": 3.565751075744629,
      "learning_rate": 1.9484801648634727e-05,
      "loss": 1.4679,
      "step": 200
    },
    {
      "epoch": 0.19319938176197837,
      "grad_norm": 6.634497165679932,
      "learning_rate": 1.9356002060793406e-05,
      "loss": 1.3633,
      "step": 250
    },
    {
      "epoch": 0.23183925811437403,
      "grad_norm": 3.257875442504883,
      "learning_rate": 1.9227202472952088e-05,
      "loss": 1.3823,
      "step": 300
    },
    {
      "epoch": 0.2704791344667697,
      "grad_norm": 4.6316399574279785,
      "learning_rate": 1.909840288511077e-05,
      "loss": 1.259,
      "step": 350
    },
    {
      "epoch": 0.3091190108191654,
      "grad_norm": 4.728428363800049,
      "learning_rate": 1.896960329726945e-05,
      "loss": 1.2159,
      "step": 400
    },
    {
      "epoch": 0.34775888717156106,
      "grad_norm": 5.232150554656982,
      "learning_rate": 1.884080370942813e-05,
      "loss": 1.1658,
      "step": 450
    },
    {
      "epoch": 0.38639876352395675,
      "grad_norm": 6.108499050140381,
      "learning_rate": 1.8712004121586813e-05,
      "loss": 1.0815,
      "step": 500
    },
    {
      "epoch": 0.4250386398763524,
      "grad_norm": 7.261651039123535,
      "learning_rate": 1.8583204533745492e-05,
      "loss": 1.0229,
      "step": 550
    },
    {
      "epoch": 0.46367851622874806,
      "grad_norm": 4.5276713371276855,
      "learning_rate": 1.8454404945904174e-05,
      "loss": 1.0867,
      "step": 600
    },
    {
      "epoch": 0.5023183925811437,
      "grad_norm": 5.0770087242126465,
      "learning_rate": 1.8325605358062856e-05,
      "loss": 0.9928,
      "step": 650
    },
    {
      "epoch": 0.5409582689335394,
      "grad_norm": 7.547360420227051,
      "learning_rate": 1.8199381761978363e-05,
      "loss": 0.953,
      "step": 700
    },
    {
      "epoch": 0.5795981452859351,
      "grad_norm": 13.589530944824219,
      "learning_rate": 1.8070582174137045e-05,
      "loss": 0.8392,
      "step": 750
    },
    {
      "epoch": 0.6182380216383307,
      "grad_norm": 5.567636013031006,
      "learning_rate": 1.7941782586295727e-05,
      "loss": 0.9502,
      "step": 800
    },
    {
      "epoch": 0.6568778979907264,
      "grad_norm": 7.520370006561279,
      "learning_rate": 1.7812982998454406e-05,
      "loss": 0.8334,
      "step": 850
    },
    {
      "epoch": 0.6955177743431221,
      "grad_norm": 3.375007152557373,
      "learning_rate": 1.7684183410613088e-05,
      "loss": 0.8254,
      "step": 900
    },
    {
      "epoch": 0.7341576506955177,
      "grad_norm": 7.63689661026001,
      "learning_rate": 1.7555383822771767e-05,
      "loss": 0.8196,
      "step": 950
    },
    {
      "epoch": 0.7727975270479135,
      "grad_norm": 7.143060684204102,
      "learning_rate": 1.742658423493045e-05,
      "loss": 0.7776,
      "step": 1000
    },
    {
      "epoch": 0.8114374034003091,
      "grad_norm": 7.10257625579834,
      "learning_rate": 1.729778464708913e-05,
      "loss": 0.7452,
      "step": 1050
    },
    {
      "epoch": 0.8500772797527048,
      "grad_norm": 7.860701084136963,
      "learning_rate": 1.716898505924781e-05,
      "loss": 0.7994,
      "step": 1100
    },
    {
      "epoch": 0.8887171561051005,
      "grad_norm": 5.768734931945801,
      "learning_rate": 1.7040185471406492e-05,
      "loss": 0.6621,
      "step": 1150
    },
    {
      "epoch": 0.9273570324574961,
      "grad_norm": 7.68084716796875,
      "learning_rate": 1.6911385883565174e-05,
      "loss": 0.7234,
      "step": 1200
    },
    {
      "epoch": 0.9659969088098919,
      "grad_norm": 5.9531450271606445,
      "learning_rate": 1.6782586295723857e-05,
      "loss": 0.7506,
      "step": 1250
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.4595070422535211,
      "eval_loss": 1.30390465259552,
      "eval_macro_f1": 0.4901055944533687,
      "eval_macro_precision": 0.4944337964473068,
      "eval_macro_recall": 0.5330167769393896,
      "eval_runtime": 6.4871,
      "eval_samples_per_second": 262.676,
      "eval_steps_per_second": 16.494,
      "step": 1294
    },
    {
      "epoch": 1.0046367851622875,
      "grad_norm": 3.4278295040130615,
      "learning_rate": 1.6653786707882535e-05,
      "loss": 0.7248,
      "step": 1300
    },
    {
      "epoch": 1.0432766615146831,
      "grad_norm": 9.05359935760498,
      "learning_rate": 1.6524987120041218e-05,
      "loss": 0.6148,
      "step": 1350
    },
    {
      "epoch": 1.0819165378670788,
      "grad_norm": 6.70934534072876,
      "learning_rate": 1.63961875321999e-05,
      "loss": 0.6578,
      "step": 1400
    },
    {
      "epoch": 1.1205564142194744,
      "grad_norm": 6.173154830932617,
      "learning_rate": 1.6269963936115406e-05,
      "loss": 0.651,
      "step": 1450
    },
    {
      "epoch": 1.1591962905718702,
      "grad_norm": 7.869283199310303,
      "learning_rate": 1.614116434827409e-05,
      "loss": 0.604,
      "step": 1500
    },
    {
      "epoch": 1.1978361669242659,
      "grad_norm": 14.966734886169434,
      "learning_rate": 1.6012364760432767e-05,
      "loss": 0.6724,
      "step": 1550
    },
    {
      "epoch": 1.2364760432766615,
      "grad_norm": 6.641883850097656,
      "learning_rate": 1.588356517259145e-05,
      "loss": 0.6147,
      "step": 1600
    },
    {
      "epoch": 1.2751159196290571,
      "grad_norm": 11.193235397338867,
      "learning_rate": 1.5754765584750128e-05,
      "loss": 0.6617,
      "step": 1650
    },
    {
      "epoch": 1.3137557959814528,
      "grad_norm": 7.752575397491455,
      "learning_rate": 1.562596599690881e-05,
      "loss": 0.6044,
      "step": 1700
    },
    {
      "epoch": 1.3523956723338486,
      "grad_norm": 4.493542194366455,
      "learning_rate": 1.5497166409067492e-05,
      "loss": 0.5782,
      "step": 1750
    },
    {
      "epoch": 1.3910355486862442,
      "grad_norm": 20.533458709716797,
      "learning_rate": 1.536836682122617e-05,
      "loss": 0.5506,
      "step": 1800
    },
    {
      "epoch": 1.4296754250386399,
      "grad_norm": 6.998429298400879,
      "learning_rate": 1.5239567233384855e-05,
      "loss": 0.5958,
      "step": 1850
    },
    {
      "epoch": 1.4683153013910355,
      "grad_norm": 5.355390548706055,
      "learning_rate": 1.5110767645543536e-05,
      "loss": 0.5189,
      "step": 1900
    },
    {
      "epoch": 1.5069551777434311,
      "grad_norm": 7.058505058288574,
      "learning_rate": 1.4981968057702216e-05,
      "loss": 0.5486,
      "step": 1950
    },
    {
      "epoch": 1.545595054095827,
      "grad_norm": 6.347295761108398,
      "learning_rate": 1.4853168469860897e-05,
      "loss": 0.4892,
      "step": 2000
    },
    {
      "epoch": 1.5842349304482226,
      "grad_norm": 4.377005100250244,
      "learning_rate": 1.472436888201958e-05,
      "loss": 0.5796,
      "step": 2050
    },
    {
      "epoch": 1.6228748068006182,
      "grad_norm": 9.126433372497559,
      "learning_rate": 1.4595569294178261e-05,
      "loss": 0.5403,
      "step": 2100
    },
    {
      "epoch": 1.6615146831530139,
      "grad_norm": 10.485395431518555,
      "learning_rate": 1.4466769706336941e-05,
      "loss": 0.5036,
      "step": 2150
    },
    {
      "epoch": 1.7001545595054095,
      "grad_norm": 7.326294422149658,
      "learning_rate": 1.4337970118495622e-05,
      "loss": 0.5064,
      "step": 2200
    },
    {
      "epoch": 1.7387944358578054,
      "grad_norm": 6.521503448486328,
      "learning_rate": 1.4209170530654304e-05,
      "loss": 0.5112,
      "step": 2250
    },
    {
      "epoch": 1.7774343122102008,
      "grad_norm": 7.700993537902832,
      "learning_rate": 1.4080370942812985e-05,
      "loss": 0.5231,
      "step": 2300
    },
    {
      "epoch": 1.8160741885625966,
      "grad_norm": 7.788994312286377,
      "learning_rate": 1.3951571354971665e-05,
      "loss": 0.5314,
      "step": 2350
    },
    {
      "epoch": 1.8547140649149922,
      "grad_norm": 12.343828201293945,
      "learning_rate": 1.3822771767130347e-05,
      "loss": 0.4784,
      "step": 2400
    },
    {
      "epoch": 1.8933539412673879,
      "grad_norm": 3.6407482624053955,
      "learning_rate": 1.3693972179289028e-05,
      "loss": 0.5779,
      "step": 2450
    },
    {
      "epoch": 1.9319938176197837,
      "grad_norm": 6.038059711456299,
      "learning_rate": 1.3565172591447708e-05,
      "loss": 0.4488,
      "step": 2500
    },
    {
      "epoch": 1.9706336939721791,
      "grad_norm": 7.334692478179932,
      "learning_rate": 1.3436373003606389e-05,
      "loss": 0.5432,
      "step": 2550
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.545774647887324,
      "eval_loss": 1.2517212629318237,
      "eval_macro_f1": 0.5685217553293251,
      "eval_macro_precision": 0.6184072966143669,
      "eval_macro_recall": 0.5473055131987923,
      "eval_runtime": 6.5065,
      "eval_samples_per_second": 261.893,
      "eval_steps_per_second": 16.445,
      "step": 2588
    },
    {
      "epoch": 2.009273570324575,
      "grad_norm": 24.217159271240234,
      "learning_rate": 1.330757341576507e-05,
      "loss": 0.4809,
      "step": 2600
    },
    {
      "epoch": 2.047913446676971,
      "grad_norm": 9.134135246276855,
      "learning_rate": 1.3178773827923751e-05,
      "loss": 0.3838,
      "step": 2650
    },
    {
      "epoch": 2.0865533230293662,
      "grad_norm": 7.295632839202881,
      "learning_rate": 1.3049974240082432e-05,
      "loss": 0.407,
      "step": 2700
    },
    {
      "epoch": 2.125193199381762,
      "grad_norm": 10.10409927368164,
      "learning_rate": 1.2921174652241112e-05,
      "loss": 0.425,
      "step": 2750
    },
    {
      "epoch": 2.1638330757341575,
      "grad_norm": 15.192545890808105,
      "learning_rate": 1.2792375064399796e-05,
      "loss": 0.4085,
      "step": 2800
    },
    {
      "epoch": 2.2024729520865534,
      "grad_norm": 11.536201477050781,
      "learning_rate": 1.2663575476558477e-05,
      "loss": 0.434,
      "step": 2850
    },
    {
      "epoch": 2.2411128284389488,
      "grad_norm": 9.895380020141602,
      "learning_rate": 1.2534775888717157e-05,
      "loss": 0.3614,
      "step": 2900
    },
    {
      "epoch": 2.2797527047913446,
      "grad_norm": 14.453925132751465,
      "learning_rate": 1.2405976300875837e-05,
      "loss": 0.4008,
      "step": 2950
    },
    {
      "epoch": 2.3183925811437405,
      "grad_norm": 7.566462993621826,
      "learning_rate": 1.227717671303452e-05,
      "loss": 0.4205,
      "step": 3000
    },
    {
      "epoch": 2.357032457496136,
      "grad_norm": 5.7315239906311035,
      "learning_rate": 1.21483771251932e-05,
      "loss": 0.3755,
      "step": 3050
    },
    {
      "epoch": 2.3956723338485317,
      "grad_norm": 3.7718758583068848,
      "learning_rate": 1.201957753735188e-05,
      "loss": 0.3571,
      "step": 3100
    },
    {
      "epoch": 2.434312210200927,
      "grad_norm": 4.20660924911499,
      "learning_rate": 1.1890777949510563e-05,
      "loss": 0.4292,
      "step": 3150
    },
    {
      "epoch": 2.472952086553323,
      "grad_norm": 8.10039234161377,
      "learning_rate": 1.1761978361669243e-05,
      "loss": 0.3828,
      "step": 3200
    },
    {
      "epoch": 2.511591962905719,
      "grad_norm": 9.897796630859375,
      "learning_rate": 1.1633178773827924e-05,
      "loss": 0.4226,
      "step": 3250
    },
    {
      "epoch": 2.5502318392581143,
      "grad_norm": 3.736192464828491,
      "learning_rate": 1.1504379185986604e-05,
      "loss": 0.332,
      "step": 3300
    },
    {
      "epoch": 2.58887171561051,
      "grad_norm": 15.784611701965332,
      "learning_rate": 1.1375579598145288e-05,
      "loss": 0.423,
      "step": 3350
    },
    {
      "epoch": 2.6275115919629055,
      "grad_norm": 9.348043441772461,
      "learning_rate": 1.1246780010303969e-05,
      "loss": 0.356,
      "step": 3400
    },
    {
      "epoch": 2.6661514683153014,
      "grad_norm": 6.1740899085998535,
      "learning_rate": 1.1117980422462649e-05,
      "loss": 0.3611,
      "step": 3450
    },
    {
      "epoch": 2.704791344667697,
      "grad_norm": 9.794791221618652,
      "learning_rate": 1.098918083462133e-05,
      "loss": 0.3297,
      "step": 3500
    },
    {
      "epoch": 2.7434312210200926,
      "grad_norm": 5.786613464355469,
      "learning_rate": 1.0860381246780012e-05,
      "loss": 0.339,
      "step": 3550
    },
    {
      "epoch": 2.7820710973724885,
      "grad_norm": 9.173519134521484,
      "learning_rate": 1.0734157650695518e-05,
      "loss": 0.3528,
      "step": 3600
    },
    {
      "epoch": 2.820710973724884,
      "grad_norm": 24.346778869628906,
      "learning_rate": 1.06053580628542e-05,
      "loss": 0.3486,
      "step": 3650
    },
    {
      "epoch": 2.8593508500772797,
      "grad_norm": 10.983345031738281,
      "learning_rate": 1.0476558475012881e-05,
      "loss": 0.3315,
      "step": 3700
    },
    {
      "epoch": 2.8979907264296756,
      "grad_norm": 53.57443618774414,
      "learning_rate": 1.0347758887171561e-05,
      "loss": 0.348,
      "step": 3750
    },
    {
      "epoch": 2.936630602782071,
      "grad_norm": 13.323150634765625,
      "learning_rate": 1.0218959299330242e-05,
      "loss": 0.3196,
      "step": 3800
    },
    {
      "epoch": 2.975270479134467,
      "grad_norm": 13.358983993530273,
      "learning_rate": 1.0090159711488926e-05,
      "loss": 0.3119,
      "step": 3850
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.5528169014084507,
      "eval_loss": 1.432175636291504,
      "eval_macro_f1": 0.5888238665940767,
      "eval_macro_precision": 0.5992379486001663,
      "eval_macro_recall": 0.5935769593716568,
      "eval_runtime": 6.5173,
      "eval_samples_per_second": 261.457,
      "eval_steps_per_second": 16.418,
      "step": 3882
    },
    {
      "epoch": 3.0139103554868623,
      "grad_norm": 7.503085613250732,
      "learning_rate": 9.961360123647606e-06,
      "loss": 0.2835,
      "step": 3900
    },
    {
      "epoch": 3.052550231839258,
      "grad_norm": 14.021950721740723,
      "learning_rate": 9.832560535806287e-06,
      "loss": 0.2449,
      "step": 3950
    },
    {
      "epoch": 3.091190108191654,
      "grad_norm": 6.994258880615234,
      "learning_rate": 9.703760947964967e-06,
      "loss": 0.2657,
      "step": 4000
    },
    {
      "epoch": 3.1298299845440494,
      "grad_norm": 0.4438261389732361,
      "learning_rate": 9.574961360123648e-06,
      "loss": 0.269,
      "step": 4050
    },
    {
      "epoch": 3.1684698608964452,
      "grad_norm": 12.422362327575684,
      "learning_rate": 9.44616177228233e-06,
      "loss": 0.2743,
      "step": 4100
    },
    {
      "epoch": 3.2071097372488406,
      "grad_norm": 11.949379920959473,
      "learning_rate": 9.31736218444101e-06,
      "loss": 0.2348,
      "step": 4150
    },
    {
      "epoch": 3.2457496136012365,
      "grad_norm": 10.629465103149414,
      "learning_rate": 9.188562596599692e-06,
      "loss": 0.2555,
      "step": 4200
    },
    {
      "epoch": 3.2843894899536323,
      "grad_norm": 11.40035629272461,
      "learning_rate": 9.059763008758373e-06,
      "loss": 0.2738,
      "step": 4250
    },
    {
      "epoch": 3.3230293663060277,
      "grad_norm": 18.268178939819336,
      "learning_rate": 8.930963420917053e-06,
      "loss": 0.2306,
      "step": 4300
    },
    {
      "epoch": 3.3616692426584236,
      "grad_norm": 17.91661834716797,
      "learning_rate": 8.802163833075736e-06,
      "loss": 0.2549,
      "step": 4350
    },
    {
      "epoch": 3.400309119010819,
      "grad_norm": 18.938920974731445,
      "learning_rate": 8.673364245234416e-06,
      "loss": 0.2541,
      "step": 4400
    },
    {
      "epoch": 3.438948995363215,
      "grad_norm": 25.206703186035156,
      "learning_rate": 8.544564657393098e-06,
      "loss": 0.2089,
      "step": 4450
    },
    {
      "epoch": 3.4775888717156107,
      "grad_norm": 16.5769100189209,
      "learning_rate": 8.415765069551779e-06,
      "loss": 0.2575,
      "step": 4500
    },
    {
      "epoch": 3.516228748068006,
      "grad_norm": 10.95858097076416,
      "learning_rate": 8.286965481710459e-06,
      "loss": 0.2417,
      "step": 4550
    },
    {
      "epoch": 3.554868624420402,
      "grad_norm": 11.512147903442383,
      "learning_rate": 8.15816589386914e-06,
      "loss": 0.335,
      "step": 4600
    },
    {
      "epoch": 3.5935085007727974,
      "grad_norm": 19.985721588134766,
      "learning_rate": 8.029366306027822e-06,
      "loss": 0.2302,
      "step": 4650
    },
    {
      "epoch": 3.6321483771251932,
      "grad_norm": 14.998536109924316,
      "learning_rate": 7.900566718186502e-06,
      "loss": 0.2776,
      "step": 4700
    },
    {
      "epoch": 3.670788253477589,
      "grad_norm": 11.70444107055664,
      "learning_rate": 7.771767130345184e-06,
      "loss": 0.2126,
      "step": 4750
    },
    {
      "epoch": 3.7094281298299845,
      "grad_norm": 15.146672248840332,
      "learning_rate": 7.642967542503865e-06,
      "loss": 0.2007,
      "step": 4800
    },
    {
      "epoch": 3.7480680061823803,
      "grad_norm": 11.84819221496582,
      "learning_rate": 7.514167954662545e-06,
      "loss": 0.2192,
      "step": 4850
    },
    {
      "epoch": 3.7867078825347757,
      "grad_norm": 13.79507064819336,
      "learning_rate": 7.3853683668212275e-06,
      "loss": 0.2219,
      "step": 4900
    },
    {
      "epoch": 3.8253477588871716,
      "grad_norm": 9.936540603637695,
      "learning_rate": 7.256568778979908e-06,
      "loss": 0.2171,
      "step": 4950
    },
    {
      "epoch": 3.8639876352395675,
      "grad_norm": 9.664226531982422,
      "learning_rate": 7.127769191138589e-06,
      "loss": 0.1972,
      "step": 5000
    },
    {
      "epoch": 3.902627511591963,
      "grad_norm": 10.306620597839355,
      "learning_rate": 6.99896960329727e-06,
      "loss": 0.2672,
      "step": 5050
    },
    {
      "epoch": 3.9412673879443587,
      "grad_norm": 18.50413703918457,
      "learning_rate": 6.870170015455951e-06,
      "loss": 0.2322,
      "step": 5100
    },
    {
      "epoch": 3.979907264296754,
      "grad_norm": 21.144878387451172,
      "learning_rate": 6.741370427614632e-06,
      "loss": 0.1845,
      "step": 5150
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.5892018779342723,
      "eval_loss": 1.5056415796279907,
      "eval_macro_f1": 0.6117752645542724,
      "eval_macro_precision": 0.6592362131938012,
      "eval_macro_recall": 0.5887721889146393,
      "eval_runtime": 6.4813,
      "eval_samples_per_second": 262.909,
      "eval_steps_per_second": 16.509,
      "step": 5176
    },
    {
      "epoch": 4.01854714064915,
      "grad_norm": 17.774368286132812,
      "learning_rate": 6.612570839773314e-06,
      "loss": 0.1816,
      "step": 5200
    },
    {
      "epoch": 4.057187017001546,
      "grad_norm": 2.0673863887786865,
      "learning_rate": 6.483771251931994e-06,
      "loss": 0.154,
      "step": 5250
    },
    {
      "epoch": 4.095826893353942,
      "grad_norm": 24.85019302368164,
      "learning_rate": 6.3549716640906756e-06,
      "loss": 0.1885,
      "step": 5300
    },
    {
      "epoch": 4.134466769706337,
      "grad_norm": 6.6734089851379395,
      "learning_rate": 6.226172076249356e-06,
      "loss": 0.1598,
      "step": 5350
    },
    {
      "epoch": 4.1731066460587325,
      "grad_norm": 2.6312949657440186,
      "learning_rate": 6.097372488408037e-06,
      "loss": 0.1586,
      "step": 5400
    },
    {
      "epoch": 4.211746522411128,
      "grad_norm": 27.933443069458008,
      "learning_rate": 5.968572900566718e-06,
      "loss": 0.1456,
      "step": 5450
    },
    {
      "epoch": 4.250386398763524,
      "grad_norm": 41.12582778930664,
      "learning_rate": 5.8397733127254e-06,
      "loss": 0.1633,
      "step": 5500
    },
    {
      "epoch": 4.289026275115919,
      "grad_norm": 22.273075103759766,
      "learning_rate": 5.710973724884081e-06,
      "loss": 0.2107,
      "step": 5550
    },
    {
      "epoch": 4.327666151468315,
      "grad_norm": 6.875419616699219,
      "learning_rate": 5.584750128799589e-06,
      "loss": 0.1641,
      "step": 5600
    },
    {
      "epoch": 4.366306027820711,
      "grad_norm": 8.022150039672852,
      "learning_rate": 5.455950540958269e-06,
      "loss": 0.1611,
      "step": 5650
    },
    {
      "epoch": 4.404945904173107,
      "grad_norm": 3.7091596126556396,
      "learning_rate": 5.3271509531169505e-06,
      "loss": 0.1491,
      "step": 5700
    },
    {
      "epoch": 4.443585780525503,
      "grad_norm": 24.005237579345703,
      "learning_rate": 5.198351365275631e-06,
      "loss": 0.1492,
      "step": 5750
    },
    {
      "epoch": 4.4822256568778975,
      "grad_norm": 8.16623306274414,
      "learning_rate": 5.069551777434313e-06,
      "loss": 0.1837,
      "step": 5800
    },
    {
      "epoch": 4.520865533230293,
      "grad_norm": 25.313491821289062,
      "learning_rate": 4.940752189592994e-06,
      "loss": 0.1591,
      "step": 5850
    },
    {
      "epoch": 4.559505409582689,
      "grad_norm": 14.587347030639648,
      "learning_rate": 4.811952601751675e-06,
      "loss": 0.127,
      "step": 5900
    },
    {
      "epoch": 4.598145285935085,
      "grad_norm": 4.21319580078125,
      "learning_rate": 4.683153013910356e-06,
      "loss": 0.1461,
      "step": 5950
    },
    {
      "epoch": 4.636785162287481,
      "grad_norm": 16.583250045776367,
      "learning_rate": 4.554353426069037e-06,
      "loss": 0.1723,
      "step": 6000
    },
    {
      "epoch": 4.675425038639876,
      "grad_norm": 3.59499192237854,
      "learning_rate": 4.425553838227718e-06,
      "loss": 0.1518,
      "step": 6050
    },
    {
      "epoch": 4.714064914992272,
      "grad_norm": 4.303652286529541,
      "learning_rate": 4.2967542503863994e-06,
      "loss": 0.1929,
      "step": 6100
    },
    {
      "epoch": 4.752704791344668,
      "grad_norm": 29.37989616394043,
      "learning_rate": 4.16795466254508e-06,
      "loss": 0.1591,
      "step": 6150
    },
    {
      "epoch": 4.7913446676970635,
      "grad_norm": 31.541955947875977,
      "learning_rate": 4.039155074703761e-06,
      "loss": 0.1314,
      "step": 6200
    },
    {
      "epoch": 4.829984544049459,
      "grad_norm": 1.7236465215682983,
      "learning_rate": 3.9103554868624426e-06,
      "loss": 0.12,
      "step": 6250
    },
    {
      "epoch": 4.868624420401854,
      "grad_norm": 23.97985076904297,
      "learning_rate": 3.781555899021123e-06,
      "loss": 0.1652,
      "step": 6300
    },
    {
      "epoch": 4.90726429675425,
      "grad_norm": 23.193572998046875,
      "learning_rate": 3.6527563111798048e-06,
      "loss": 0.1427,
      "step": 6350
    },
    {
      "epoch": 4.945904173106646,
      "grad_norm": 22.322751998901367,
      "learning_rate": 3.5239567233384857e-06,
      "loss": 0.1569,
      "step": 6400
    },
    {
      "epoch": 4.984544049459042,
      "grad_norm": 10.453102111816406,
      "learning_rate": 3.395157135497167e-06,
      "loss": 0.1706,
      "step": 6450
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.590962441314554,
      "eval_loss": 1.683406949043274,
      "eval_macro_f1": 0.5949874332148177,
      "eval_macro_precision": 0.6450421980471855,
      "eval_macro_recall": 0.5703631389957727,
      "eval_runtime": 6.5272,
      "eval_samples_per_second": 261.062,
      "eval_steps_per_second": 16.393,
      "step": 6470
    },
    {
      "epoch": 5.023183925811438,
      "grad_norm": 4.803323745727539,
      "learning_rate": 3.266357547655848e-06,
      "loss": 0.1154,
      "step": 6500
    },
    {
      "epoch": 5.061823802163833,
      "grad_norm": 25.005231857299805,
      "learning_rate": 3.137557959814529e-06,
      "loss": 0.1282,
      "step": 6550
    },
    {
      "epoch": 5.1004636785162285,
      "grad_norm": 0.7600101828575134,
      "learning_rate": 3.00875837197321e-06,
      "loss": 0.0827,
      "step": 6600
    },
    {
      "epoch": 5.139103554868624,
      "grad_norm": 2.038386106491089,
      "learning_rate": 2.879958784131891e-06,
      "loss": 0.1214,
      "step": 6650
    },
    {
      "epoch": 5.17774343122102,
      "grad_norm": 21.296112060546875,
      "learning_rate": 2.751159196290572e-06,
      "loss": 0.0779,
      "step": 6700
    },
    {
      "epoch": 5.216383307573416,
      "grad_norm": 14.144908905029297,
      "learning_rate": 2.6223596084492532e-06,
      "loss": 0.1404,
      "step": 6750
    },
    {
      "epoch": 5.255023183925811,
      "grad_norm": 30.20878028869629,
      "learning_rate": 2.4935600206079346e-06,
      "loss": 0.086,
      "step": 6800
    },
    {
      "epoch": 5.293663060278207,
      "grad_norm": 19.751022338867188,
      "learning_rate": 2.3647604327666155e-06,
      "loss": 0.0677,
      "step": 6850
    },
    {
      "epoch": 5.332302936630603,
      "grad_norm": 1.8327205181121826,
      "learning_rate": 2.2359608449252964e-06,
      "loss": 0.1003,
      "step": 6900
    },
    {
      "epoch": 5.370942812982999,
      "grad_norm": 29.396284103393555,
      "learning_rate": 2.1071612570839777e-06,
      "loss": 0.1339,
      "step": 6950
    },
    {
      "epoch": 5.409582689335394,
      "grad_norm": 22.65109634399414,
      "learning_rate": 1.9783616692426586e-06,
      "loss": 0.0689,
      "step": 7000
    },
    {
      "epoch": 5.448222565687789,
      "grad_norm": 0.8711058497428894,
      "learning_rate": 1.8495620814013395e-06,
      "loss": 0.1319,
      "step": 7050
    },
    {
      "epoch": 5.486862442040185,
      "grad_norm": 33.284488677978516,
      "learning_rate": 1.7207624935600206e-06,
      "loss": 0.1187,
      "step": 7100
    },
    {
      "epoch": 5.525502318392581,
      "grad_norm": 9.813301086425781,
      "learning_rate": 1.591962905718702e-06,
      "loss": 0.0894,
      "step": 7150
    },
    {
      "epoch": 5.564142194744977,
      "grad_norm": 8.424511909484863,
      "learning_rate": 1.463163317877383e-06,
      "loss": 0.0999,
      "step": 7200
    },
    {
      "epoch": 5.602782071097373,
      "grad_norm": 0.390951007604599,
      "learning_rate": 1.334363730036064e-06,
      "loss": 0.1017,
      "step": 7250
    },
    {
      "epoch": 5.641421947449768,
      "grad_norm": 37.81884002685547,
      "learning_rate": 1.205564142194745e-06,
      "loss": 0.0839,
      "step": 7300
    },
    {
      "epoch": 5.680061823802164,
      "grad_norm": 22.33325958251953,
      "learning_rate": 1.0767645543534262e-06,
      "loss": 0.106,
      "step": 7350
    },
    {
      "epoch": 5.7187017001545595,
      "grad_norm": 1.9060829877853394,
      "learning_rate": 9.479649665121073e-07,
      "loss": 0.1031,
      "step": 7400
    },
    {
      "epoch": 5.757341576506955,
      "grad_norm": 1.0884907245635986,
      "learning_rate": 8.191653786707883e-07,
      "loss": 0.0868,
      "step": 7450
    },
    {
      "epoch": 5.795981452859351,
      "grad_norm": 13.665401458740234,
      "learning_rate": 6.903657908294694e-07,
      "loss": 0.1112,
      "step": 7500
    },
    {
      "epoch": 5.834621329211746,
      "grad_norm": 48.800716400146484,
      "learning_rate": 5.615662029881505e-07,
      "loss": 0.1058,
      "step": 7550
    },
    {
      "epoch": 5.873261205564142,
      "grad_norm": 23.138395309448242,
      "learning_rate": 4.3276661514683155e-07,
      "loss": 0.0928,
      "step": 7600
    },
    {
      "epoch": 5.911901081916538,
      "grad_norm": 2.6377108097076416,
      "learning_rate": 3.0396702730551266e-07,
      "loss": 0.0738,
      "step": 7650
    },
    {
      "epoch": 5.950540958268934,
      "grad_norm": 1.9808526039123535,
      "learning_rate": 1.7516743946419372e-07,
      "loss": 0.1123,
      "step": 7700
    },
    {
      "epoch": 5.9891808346213296,
      "grad_norm": 22.99396324157715,
      "learning_rate": 4.894384337970119e-08,
      "loss": 0.1124,
      "step": 7750
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.6062206572769953,
      "eval_loss": 1.7970985174179077,
      "eval_macro_f1": 0.6116295065764386,
      "eval_macro_precision": 0.6682412378146259,
      "eval_macro_recall": 0.5854611650914492,
      "eval_runtime": 6.4639,
      "eval_samples_per_second": 263.62,
      "eval_steps_per_second": 16.554,
      "step": 7764
    }
  ],
  "logging_steps": 50,
  "max_steps": 7764,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2335136738048e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}

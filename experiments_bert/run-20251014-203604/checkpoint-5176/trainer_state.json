{
  "best_metric": 0.6117752645542724,
  "best_model_checkpoint": "experiments_bert/run-20251014-203604/checkpoint-5176",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 5176,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03863987635239567,
      "grad_norm": 2.792250633239746,
      "learning_rate": 1.9871200412158684e-05,
      "loss": 2.1339,
      "step": 50
    },
    {
      "epoch": 0.07727975270479134,
      "grad_norm": 3.028048038482666,
      "learning_rate": 1.9742400824317366e-05,
      "loss": 1.7446,
      "step": 100
    },
    {
      "epoch": 0.11591962905718702,
      "grad_norm": 4.253394603729248,
      "learning_rate": 1.9613601236476045e-05,
      "loss": 1.5603,
      "step": 150
    },
    {
      "epoch": 0.1545595054095827,
      "grad_norm": 3.565751075744629,
      "learning_rate": 1.9484801648634727e-05,
      "loss": 1.4679,
      "step": 200
    },
    {
      "epoch": 0.19319938176197837,
      "grad_norm": 6.634497165679932,
      "learning_rate": 1.9356002060793406e-05,
      "loss": 1.3633,
      "step": 250
    },
    {
      "epoch": 0.23183925811437403,
      "grad_norm": 3.257875442504883,
      "learning_rate": 1.9227202472952088e-05,
      "loss": 1.3823,
      "step": 300
    },
    {
      "epoch": 0.2704791344667697,
      "grad_norm": 4.6316399574279785,
      "learning_rate": 1.909840288511077e-05,
      "loss": 1.259,
      "step": 350
    },
    {
      "epoch": 0.3091190108191654,
      "grad_norm": 4.728428363800049,
      "learning_rate": 1.896960329726945e-05,
      "loss": 1.2159,
      "step": 400
    },
    {
      "epoch": 0.34775888717156106,
      "grad_norm": 5.232150554656982,
      "learning_rate": 1.884080370942813e-05,
      "loss": 1.1658,
      "step": 450
    },
    {
      "epoch": 0.38639876352395675,
      "grad_norm": 6.108499050140381,
      "learning_rate": 1.8712004121586813e-05,
      "loss": 1.0815,
      "step": 500
    },
    {
      "epoch": 0.4250386398763524,
      "grad_norm": 7.261651039123535,
      "learning_rate": 1.8583204533745492e-05,
      "loss": 1.0229,
      "step": 550
    },
    {
      "epoch": 0.46367851622874806,
      "grad_norm": 4.5276713371276855,
      "learning_rate": 1.8454404945904174e-05,
      "loss": 1.0867,
      "step": 600
    },
    {
      "epoch": 0.5023183925811437,
      "grad_norm": 5.0770087242126465,
      "learning_rate": 1.8325605358062856e-05,
      "loss": 0.9928,
      "step": 650
    },
    {
      "epoch": 0.5409582689335394,
      "grad_norm": 7.547360420227051,
      "learning_rate": 1.8199381761978363e-05,
      "loss": 0.953,
      "step": 700
    },
    {
      "epoch": 0.5795981452859351,
      "grad_norm": 13.589530944824219,
      "learning_rate": 1.8070582174137045e-05,
      "loss": 0.8392,
      "step": 750
    },
    {
      "epoch": 0.6182380216383307,
      "grad_norm": 5.567636013031006,
      "learning_rate": 1.7941782586295727e-05,
      "loss": 0.9502,
      "step": 800
    },
    {
      "epoch": 0.6568778979907264,
      "grad_norm": 7.520370006561279,
      "learning_rate": 1.7812982998454406e-05,
      "loss": 0.8334,
      "step": 850
    },
    {
      "epoch": 0.6955177743431221,
      "grad_norm": 3.375007152557373,
      "learning_rate": 1.7684183410613088e-05,
      "loss": 0.8254,
      "step": 900
    },
    {
      "epoch": 0.7341576506955177,
      "grad_norm": 7.63689661026001,
      "learning_rate": 1.7555383822771767e-05,
      "loss": 0.8196,
      "step": 950
    },
    {
      "epoch": 0.7727975270479135,
      "grad_norm": 7.143060684204102,
      "learning_rate": 1.742658423493045e-05,
      "loss": 0.7776,
      "step": 1000
    },
    {
      "epoch": 0.8114374034003091,
      "grad_norm": 7.10257625579834,
      "learning_rate": 1.729778464708913e-05,
      "loss": 0.7452,
      "step": 1050
    },
    {
      "epoch": 0.8500772797527048,
      "grad_norm": 7.860701084136963,
      "learning_rate": 1.716898505924781e-05,
      "loss": 0.7994,
      "step": 1100
    },
    {
      "epoch": 0.8887171561051005,
      "grad_norm": 5.768734931945801,
      "learning_rate": 1.7040185471406492e-05,
      "loss": 0.6621,
      "step": 1150
    },
    {
      "epoch": 0.9273570324574961,
      "grad_norm": 7.68084716796875,
      "learning_rate": 1.6911385883565174e-05,
      "loss": 0.7234,
      "step": 1200
    },
    {
      "epoch": 0.9659969088098919,
      "grad_norm": 5.9531450271606445,
      "learning_rate": 1.6782586295723857e-05,
      "loss": 0.7506,
      "step": 1250
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.4595070422535211,
      "eval_loss": 1.30390465259552,
      "eval_macro_f1": 0.4901055944533687,
      "eval_macro_precision": 0.4944337964473068,
      "eval_macro_recall": 0.5330167769393896,
      "eval_runtime": 6.4871,
      "eval_samples_per_second": 262.676,
      "eval_steps_per_second": 16.494,
      "step": 1294
    },
    {
      "epoch": 1.0046367851622875,
      "grad_norm": 3.4278295040130615,
      "learning_rate": 1.6653786707882535e-05,
      "loss": 0.7248,
      "step": 1300
    },
    {
      "epoch": 1.0432766615146831,
      "grad_norm": 9.05359935760498,
      "learning_rate": 1.6524987120041218e-05,
      "loss": 0.6148,
      "step": 1350
    },
    {
      "epoch": 1.0819165378670788,
      "grad_norm": 6.70934534072876,
      "learning_rate": 1.63961875321999e-05,
      "loss": 0.6578,
      "step": 1400
    },
    {
      "epoch": 1.1205564142194744,
      "grad_norm": 6.173154830932617,
      "learning_rate": 1.6269963936115406e-05,
      "loss": 0.651,
      "step": 1450
    },
    {
      "epoch": 1.1591962905718702,
      "grad_norm": 7.869283199310303,
      "learning_rate": 1.614116434827409e-05,
      "loss": 0.604,
      "step": 1500
    },
    {
      "epoch": 1.1978361669242659,
      "grad_norm": 14.966734886169434,
      "learning_rate": 1.6012364760432767e-05,
      "loss": 0.6724,
      "step": 1550
    },
    {
      "epoch": 1.2364760432766615,
      "grad_norm": 6.641883850097656,
      "learning_rate": 1.588356517259145e-05,
      "loss": 0.6147,
      "step": 1600
    },
    {
      "epoch": 1.2751159196290571,
      "grad_norm": 11.193235397338867,
      "learning_rate": 1.5754765584750128e-05,
      "loss": 0.6617,
      "step": 1650
    },
    {
      "epoch": 1.3137557959814528,
      "grad_norm": 7.752575397491455,
      "learning_rate": 1.562596599690881e-05,
      "loss": 0.6044,
      "step": 1700
    },
    {
      "epoch": 1.3523956723338486,
      "grad_norm": 4.493542194366455,
      "learning_rate": 1.5497166409067492e-05,
      "loss": 0.5782,
      "step": 1750
    },
    {
      "epoch": 1.3910355486862442,
      "grad_norm": 20.533458709716797,
      "learning_rate": 1.536836682122617e-05,
      "loss": 0.5506,
      "step": 1800
    },
    {
      "epoch": 1.4296754250386399,
      "grad_norm": 6.998429298400879,
      "learning_rate": 1.5239567233384855e-05,
      "loss": 0.5958,
      "step": 1850
    },
    {
      "epoch": 1.4683153013910355,
      "grad_norm": 5.355390548706055,
      "learning_rate": 1.5110767645543536e-05,
      "loss": 0.5189,
      "step": 1900
    },
    {
      "epoch": 1.5069551777434311,
      "grad_norm": 7.058505058288574,
      "learning_rate": 1.4981968057702216e-05,
      "loss": 0.5486,
      "step": 1950
    },
    {
      "epoch": 1.545595054095827,
      "grad_norm": 6.347295761108398,
      "learning_rate": 1.4853168469860897e-05,
      "loss": 0.4892,
      "step": 2000
    },
    {
      "epoch": 1.5842349304482226,
      "grad_norm": 4.377005100250244,
      "learning_rate": 1.472436888201958e-05,
      "loss": 0.5796,
      "step": 2050
    },
    {
      "epoch": 1.6228748068006182,
      "grad_norm": 9.126433372497559,
      "learning_rate": 1.4595569294178261e-05,
      "loss": 0.5403,
      "step": 2100
    },
    {
      "epoch": 1.6615146831530139,
      "grad_norm": 10.485395431518555,
      "learning_rate": 1.4466769706336941e-05,
      "loss": 0.5036,
      "step": 2150
    },
    {
      "epoch": 1.7001545595054095,
      "grad_norm": 7.326294422149658,
      "learning_rate": 1.4337970118495622e-05,
      "loss": 0.5064,
      "step": 2200
    },
    {
      "epoch": 1.7387944358578054,
      "grad_norm": 6.521503448486328,
      "learning_rate": 1.4209170530654304e-05,
      "loss": 0.5112,
      "step": 2250
    },
    {
      "epoch": 1.7774343122102008,
      "grad_norm": 7.700993537902832,
      "learning_rate": 1.4080370942812985e-05,
      "loss": 0.5231,
      "step": 2300
    },
    {
      "epoch": 1.8160741885625966,
      "grad_norm": 7.788994312286377,
      "learning_rate": 1.3951571354971665e-05,
      "loss": 0.5314,
      "step": 2350
    },
    {
      "epoch": 1.8547140649149922,
      "grad_norm": 12.343828201293945,
      "learning_rate": 1.3822771767130347e-05,
      "loss": 0.4784,
      "step": 2400
    },
    {
      "epoch": 1.8933539412673879,
      "grad_norm": 3.6407482624053955,
      "learning_rate": 1.3693972179289028e-05,
      "loss": 0.5779,
      "step": 2450
    },
    {
      "epoch": 1.9319938176197837,
      "grad_norm": 6.038059711456299,
      "learning_rate": 1.3565172591447708e-05,
      "loss": 0.4488,
      "step": 2500
    },
    {
      "epoch": 1.9706336939721791,
      "grad_norm": 7.334692478179932,
      "learning_rate": 1.3436373003606389e-05,
      "loss": 0.5432,
      "step": 2550
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.545774647887324,
      "eval_loss": 1.2517212629318237,
      "eval_macro_f1": 0.5685217553293251,
      "eval_macro_precision": 0.6184072966143669,
      "eval_macro_recall": 0.5473055131987923,
      "eval_runtime": 6.5065,
      "eval_samples_per_second": 261.893,
      "eval_steps_per_second": 16.445,
      "step": 2588
    },
    {
      "epoch": 2.009273570324575,
      "grad_norm": 24.217159271240234,
      "learning_rate": 1.330757341576507e-05,
      "loss": 0.4809,
      "step": 2600
    },
    {
      "epoch": 2.047913446676971,
      "grad_norm": 9.134135246276855,
      "learning_rate": 1.3178773827923751e-05,
      "loss": 0.3838,
      "step": 2650
    },
    {
      "epoch": 2.0865533230293662,
      "grad_norm": 7.295632839202881,
      "learning_rate": 1.3049974240082432e-05,
      "loss": 0.407,
      "step": 2700
    },
    {
      "epoch": 2.125193199381762,
      "grad_norm": 10.10409927368164,
      "learning_rate": 1.2921174652241112e-05,
      "loss": 0.425,
      "step": 2750
    },
    {
      "epoch": 2.1638330757341575,
      "grad_norm": 15.192545890808105,
      "learning_rate": 1.2792375064399796e-05,
      "loss": 0.4085,
      "step": 2800
    },
    {
      "epoch": 2.2024729520865534,
      "grad_norm": 11.536201477050781,
      "learning_rate": 1.2663575476558477e-05,
      "loss": 0.434,
      "step": 2850
    },
    {
      "epoch": 2.2411128284389488,
      "grad_norm": 9.895380020141602,
      "learning_rate": 1.2534775888717157e-05,
      "loss": 0.3614,
      "step": 2900
    },
    {
      "epoch": 2.2797527047913446,
      "grad_norm": 14.453925132751465,
      "learning_rate": 1.2405976300875837e-05,
      "loss": 0.4008,
      "step": 2950
    },
    {
      "epoch": 2.3183925811437405,
      "grad_norm": 7.566462993621826,
      "learning_rate": 1.227717671303452e-05,
      "loss": 0.4205,
      "step": 3000
    },
    {
      "epoch": 2.357032457496136,
      "grad_norm": 5.7315239906311035,
      "learning_rate": 1.21483771251932e-05,
      "loss": 0.3755,
      "step": 3050
    },
    {
      "epoch": 2.3956723338485317,
      "grad_norm": 3.7718758583068848,
      "learning_rate": 1.201957753735188e-05,
      "loss": 0.3571,
      "step": 3100
    },
    {
      "epoch": 2.434312210200927,
      "grad_norm": 4.20660924911499,
      "learning_rate": 1.1890777949510563e-05,
      "loss": 0.4292,
      "step": 3150
    },
    {
      "epoch": 2.472952086553323,
      "grad_norm": 8.10039234161377,
      "learning_rate": 1.1761978361669243e-05,
      "loss": 0.3828,
      "step": 3200
    },
    {
      "epoch": 2.511591962905719,
      "grad_norm": 9.897796630859375,
      "learning_rate": 1.1633178773827924e-05,
      "loss": 0.4226,
      "step": 3250
    },
    {
      "epoch": 2.5502318392581143,
      "grad_norm": 3.736192464828491,
      "learning_rate": 1.1504379185986604e-05,
      "loss": 0.332,
      "step": 3300
    },
    {
      "epoch": 2.58887171561051,
      "grad_norm": 15.784611701965332,
      "learning_rate": 1.1375579598145288e-05,
      "loss": 0.423,
      "step": 3350
    },
    {
      "epoch": 2.6275115919629055,
      "grad_norm": 9.348043441772461,
      "learning_rate": 1.1246780010303969e-05,
      "loss": 0.356,
      "step": 3400
    },
    {
      "epoch": 2.6661514683153014,
      "grad_norm": 6.1740899085998535,
      "learning_rate": 1.1117980422462649e-05,
      "loss": 0.3611,
      "step": 3450
    },
    {
      "epoch": 2.704791344667697,
      "grad_norm": 9.794791221618652,
      "learning_rate": 1.098918083462133e-05,
      "loss": 0.3297,
      "step": 3500
    },
    {
      "epoch": 2.7434312210200926,
      "grad_norm": 5.786613464355469,
      "learning_rate": 1.0860381246780012e-05,
      "loss": 0.339,
      "step": 3550
    },
    {
      "epoch": 2.7820710973724885,
      "grad_norm": 9.173519134521484,
      "learning_rate": 1.0734157650695518e-05,
      "loss": 0.3528,
      "step": 3600
    },
    {
      "epoch": 2.820710973724884,
      "grad_norm": 24.346778869628906,
      "learning_rate": 1.06053580628542e-05,
      "loss": 0.3486,
      "step": 3650
    },
    {
      "epoch": 2.8593508500772797,
      "grad_norm": 10.983345031738281,
      "learning_rate": 1.0476558475012881e-05,
      "loss": 0.3315,
      "step": 3700
    },
    {
      "epoch": 2.8979907264296756,
      "grad_norm": 53.57443618774414,
      "learning_rate": 1.0347758887171561e-05,
      "loss": 0.348,
      "step": 3750
    },
    {
      "epoch": 2.936630602782071,
      "grad_norm": 13.323150634765625,
      "learning_rate": 1.0218959299330242e-05,
      "loss": 0.3196,
      "step": 3800
    },
    {
      "epoch": 2.975270479134467,
      "grad_norm": 13.358983993530273,
      "learning_rate": 1.0090159711488926e-05,
      "loss": 0.3119,
      "step": 3850
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.5528169014084507,
      "eval_loss": 1.432175636291504,
      "eval_macro_f1": 0.5888238665940767,
      "eval_macro_precision": 0.5992379486001663,
      "eval_macro_recall": 0.5935769593716568,
      "eval_runtime": 6.5173,
      "eval_samples_per_second": 261.457,
      "eval_steps_per_second": 16.418,
      "step": 3882
    },
    {
      "epoch": 3.0139103554868623,
      "grad_norm": 7.503085613250732,
      "learning_rate": 9.961360123647606e-06,
      "loss": 0.2835,
      "step": 3900
    },
    {
      "epoch": 3.052550231839258,
      "grad_norm": 14.021950721740723,
      "learning_rate": 9.832560535806287e-06,
      "loss": 0.2449,
      "step": 3950
    },
    {
      "epoch": 3.091190108191654,
      "grad_norm": 6.994258880615234,
      "learning_rate": 9.703760947964967e-06,
      "loss": 0.2657,
      "step": 4000
    },
    {
      "epoch": 3.1298299845440494,
      "grad_norm": 0.4438261389732361,
      "learning_rate": 9.574961360123648e-06,
      "loss": 0.269,
      "step": 4050
    },
    {
      "epoch": 3.1684698608964452,
      "grad_norm": 12.422362327575684,
      "learning_rate": 9.44616177228233e-06,
      "loss": 0.2743,
      "step": 4100
    },
    {
      "epoch": 3.2071097372488406,
      "grad_norm": 11.949379920959473,
      "learning_rate": 9.31736218444101e-06,
      "loss": 0.2348,
      "step": 4150
    },
    {
      "epoch": 3.2457496136012365,
      "grad_norm": 10.629465103149414,
      "learning_rate": 9.188562596599692e-06,
      "loss": 0.2555,
      "step": 4200
    },
    {
      "epoch": 3.2843894899536323,
      "grad_norm": 11.40035629272461,
      "learning_rate": 9.059763008758373e-06,
      "loss": 0.2738,
      "step": 4250
    },
    {
      "epoch": 3.3230293663060277,
      "grad_norm": 18.268178939819336,
      "learning_rate": 8.930963420917053e-06,
      "loss": 0.2306,
      "step": 4300
    },
    {
      "epoch": 3.3616692426584236,
      "grad_norm": 17.91661834716797,
      "learning_rate": 8.802163833075736e-06,
      "loss": 0.2549,
      "step": 4350
    },
    {
      "epoch": 3.400309119010819,
      "grad_norm": 18.938920974731445,
      "learning_rate": 8.673364245234416e-06,
      "loss": 0.2541,
      "step": 4400
    },
    {
      "epoch": 3.438948995363215,
      "grad_norm": 25.206703186035156,
      "learning_rate": 8.544564657393098e-06,
      "loss": 0.2089,
      "step": 4450
    },
    {
      "epoch": 3.4775888717156107,
      "grad_norm": 16.5769100189209,
      "learning_rate": 8.415765069551779e-06,
      "loss": 0.2575,
      "step": 4500
    },
    {
      "epoch": 3.516228748068006,
      "grad_norm": 10.95858097076416,
      "learning_rate": 8.286965481710459e-06,
      "loss": 0.2417,
      "step": 4550
    },
    {
      "epoch": 3.554868624420402,
      "grad_norm": 11.512147903442383,
      "learning_rate": 8.15816589386914e-06,
      "loss": 0.335,
      "step": 4600
    },
    {
      "epoch": 3.5935085007727974,
      "grad_norm": 19.985721588134766,
      "learning_rate": 8.029366306027822e-06,
      "loss": 0.2302,
      "step": 4650
    },
    {
      "epoch": 3.6321483771251932,
      "grad_norm": 14.998536109924316,
      "learning_rate": 7.900566718186502e-06,
      "loss": 0.2776,
      "step": 4700
    },
    {
      "epoch": 3.670788253477589,
      "grad_norm": 11.70444107055664,
      "learning_rate": 7.771767130345184e-06,
      "loss": 0.2126,
      "step": 4750
    },
    {
      "epoch": 3.7094281298299845,
      "grad_norm": 15.146672248840332,
      "learning_rate": 7.642967542503865e-06,
      "loss": 0.2007,
      "step": 4800
    },
    {
      "epoch": 3.7480680061823803,
      "grad_norm": 11.84819221496582,
      "learning_rate": 7.514167954662545e-06,
      "loss": 0.2192,
      "step": 4850
    },
    {
      "epoch": 3.7867078825347757,
      "grad_norm": 13.79507064819336,
      "learning_rate": 7.3853683668212275e-06,
      "loss": 0.2219,
      "step": 4900
    },
    {
      "epoch": 3.8253477588871716,
      "grad_norm": 9.936540603637695,
      "learning_rate": 7.256568778979908e-06,
      "loss": 0.2171,
      "step": 4950
    },
    {
      "epoch": 3.8639876352395675,
      "grad_norm": 9.664226531982422,
      "learning_rate": 7.127769191138589e-06,
      "loss": 0.1972,
      "step": 5000
    },
    {
      "epoch": 3.902627511591963,
      "grad_norm": 10.306620597839355,
      "learning_rate": 6.99896960329727e-06,
      "loss": 0.2672,
      "step": 5050
    },
    {
      "epoch": 3.9412673879443587,
      "grad_norm": 18.50413703918457,
      "learning_rate": 6.870170015455951e-06,
      "loss": 0.2322,
      "step": 5100
    },
    {
      "epoch": 3.979907264296754,
      "grad_norm": 21.144878387451172,
      "learning_rate": 6.741370427614632e-06,
      "loss": 0.1845,
      "step": 5150
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.5892018779342723,
      "eval_loss": 1.5056415796279907,
      "eval_macro_f1": 0.6117752645542724,
      "eval_macro_precision": 0.6592362131938012,
      "eval_macro_recall": 0.5887721889146393,
      "eval_runtime": 6.4813,
      "eval_samples_per_second": 262.909,
      "eval_steps_per_second": 16.509,
      "step": 5176
    }
  ],
  "logging_steps": 50,
  "max_steps": 7764,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8223424492032000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
